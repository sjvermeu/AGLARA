<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:id="platform" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Platform selection</title>

  <section>
    <title>Gentoo Linux</title>

    <para>Within the reference architecture, we standardize on Gentoo Linux.
    Standardization on a single platform allows organizations to keep the cost
    sufficiently low, but also offers the advantage that you can use solutions
    specific for the platform, rather than having to look for solutions that
    must support a multitude of platforms. Of course, the choice of picking
    Gentoo Linux here might seem weird - why not CentOS (as that has a
    possible commercial backing towards RedHat Enterprise Linux when
    needed)?</para>

    <itemizedlist>
      <listitem>
        <para>First of all - the author is a Gentoo Linux developer. Its the
        distribution he know the best.</para>

        <para>But in light of a (fictional) company, it might also be because
        its current (fictional) engineers are all Gentoo Linux developers, or
        because it has ties with regional Gentoo Linux supporting services. In
        light of many organizations, when there is choice between Linux
        distributions, one thing to consider is which distribution your
        engineers are most likely to work with. Alright, asking them will
        probably result in some heavy fighting to see which distribution is
        best (perhaps you can use the <link
        xlink:href="https://en.wikipedia.org/wiki/Condorcet_method">Condorcet
        method</link> to find the best selection), but picking a distribution
        your engineers are less eager to support will result in bad
        administration anyhow.</para>
      </listitem>

      <listitem>
        <para>The reason to use CentOS (RHEL) could be to have certified
        hosting of certain products which are only supported on RHEL (or
        similar). However, because we will only use free software solutions,
        this is no requirement for our case. But it is understandable that
        companies that do run proprietary software choose a distribution that
        is supported by their vendors.</para>
      </listitem>

      <listitem>
        <para>Gentoo Linux offers a fairly flexible approach on supported
        features. Thanks to a good balance of USE flags, we can install
        servers and services that offer just those services we need, without
        any additional dependencies or features that we will have to disable
        (in order to secure the services) anyhow. This leads to somewhat
        better performance, but also to a saving in storage requirements,
        patching frequency, etc. Gentoo is also quite fast in adopting new
        technologies, which might help the business stand out against the
        other competitors.</para>
      </listitem>

      <listitem>
        <para>Gentoo uses rolling upgrades. That might not seem like a good
        way in enterprises, but allow me to convince you - it is. If an
        organization is doing things right, it is already distributing and
        rolling out patches and minor upgrades regularly. With Gentoo, this
        process is a bit more intrusive (as it might contain larger changes as
        well) but because the administrators are used to it, it is very much
        under control. As a result, whereas other organizations have to
        schedule large (expensive and time-consuming) upgrades every 3 to 5
        years, Gentoo just moves along...</para>
      </listitem>

      <listitem>
        <para>Gentoo has a subproject called Gentoo Hardened who strives to
        provide, implement and support security-improving patches on the base
        system. This project has always been a fore-runner in security-related
        risk mitigation strategies.</para>
      </listitem>
    </itemizedlist>

    <para>Of course, because this book is called "A Gentoo Linux Advanced
    Reference Architecture", it would be weird to have it talk about another
    distribution, wouldn't it?</para>

    <para>Now, the selection of Gentoo Linux also has a few challenges up its
    sleeve.</para>

    <itemizedlist>
      <listitem>
        <para>Gentoo Linux is primarily a source-based distribution, which is
        frequently frowned upon in the enterprise market. Weirdly enough, they
        don't find it strange that their development and operational teams
        keep on building frameworks and tools themselves because of lack of
        good tools. This is exactly where Gentoo Linux outshines the others:
        it offers many tools out-of-the-box to support every possible
        requirement.</para>

        <para>To reduce the impact of its source-only stigma, we will dedicate
        a chapter in this book on the use of build servers and binhost support
        for improved manageability.</para>
      </listitem>

      <listitem>
        <para>Because of its source-based nature, it also provides all the
        tools for malicious users to build exploits on the server
        itself.</para>

        <para>In my opinion, it is fairly easy to hide the compiler or at
        least have some group-based access control on it. But regardless of
        that - the moment a malicious user has (shell) access to your system,
        you're screwed anyhow. It is fairly easy to transfer files (even full
        applications) towards the system then.</para>

        <para>To reduce possible impact here, we will be using a Mandatory
        Access Control system which isolates processes and even users,
        confining them to just what they need to get their job done.</para>
      </listitem>
    </itemizedlist>

    <para>We will standardize on the x86_64 architecture (amd64), partially
    because it is the widest known in the Gentoo Linux development community,
    but also because its hardware is widely available and sufficiently cheap.
    It is also a processor architecture that is constantly evolving and has
    many vendors working on it (less monopolizing strategies) which makes it a
    better platform for consumers in my opinion.</para>

    <para>That being said, we'll also use the no-multilib approach in Gentoo
    Linux. Systems need to be fully x86_64 driven, partially for
    standardization as well, but also to make debugging easier. The fewer
    special cases you need to think about, the faster you can resolve
    problems. Generally though, this gives little (to no) additional advantage
    towards a multilib profile. But as this is a reference architecture, I'll
    stick with this.</para>
  </section>

  <section>
    <title>Virtualization using KVM</title>

    <para>When possible, we will use virtualization. As virtualization
    platform, we will choose KVM as it offers many interesting features (both
    for development as well as larger enterprise usability) and is quite
    popular in the Linux development (and user) community. Other
    virtualization techniques that can be used are Xen or Virtualbox. Within
    Gentoo Linux, KVM is a popular and much-used virtualization
    technology.</para>

    <section>
      <title>Why virtualize</title>

      <para>Virtualization has been around for quite some time. Early
      mainframe installations already had a sort of isolation that is not far
      off from virtualization nowadays. However, virtualization is not just a
      mainframe concept anymore - most larger enterprises are already fully
      working on the virtualization of their stacks. Products like
      VMWare<indexterm>
          <primary>VMWare</primary>
        </indexterm> have popularized virtualization in the enterprise, and
      other hypervisors like KVM, VirtualBox, Xen and more are trying to get a
      piece of the cacke.</para>

      <para>To help administrators manage the virtual guests that are running
      on dozens of hosts, frameworks have emerged that lift some of the
      management tasks to a higher level. These frameworks offer automated
      generation of new guests, simplified configuration of the instances,
      remote management of guests. Some of them even support maintenance
      activities, such as moving guests from one host to another, or monitor
      the resource consumption of guests to find a good balance between
      running guests and available hosts.</para>

      <para>In Gentoo, many of these virtualization frameworks are
      supported.</para>

      <para>The first one is <package>app-emulation/libvirt</package> and is
      RedHat's virtualization management platform. The hypervisor systems run
      the libvirt daemon which manages the virtual guests as well as storage
      and other settings, and the administrator remotely connects to the
      various hypervisor systems through the
      <package>app-emulation/virt-manager</package> application. It has
      support for SELinux through its s(ecure)Virt(ualization) feature. To do
      so, it does require the MCS SELinux policy. Libvirt is also being used
      by many other frameworks (like oVirt, Archipel, Abiquo and more).</para>

      <para>Another one that is gaining momentum is
      <package>app-emulation/ganeti</package> and is backed by Google. It is
      foremost a command-line driven method but is well capable of handling
      dozens and dozens of hypervisor systems. It supports simplified
      fail-over on top of DRBD and makes an abstraction of the running hosts
      versus the guests. It bundles a set of hosts (which it calls nodes) in
      logical groups called clusters. The guests (instances) are then spread
      across the nodes in the cluster, and the administrator manages the
      cluster remotely.</para>

      <para>Using virtualization has a whole set of advantages of which I'll
      try to mention a few in the next paragraphs. I will use the term
      <emphasis>host</emphasis> when talking about the host operating system
      (the one running or directly managing the hypervisor software) and
      <emphasis>guest</emphasis> for the virtualized operating system
      instances (that are running on the host).</para>

      <section>
        <title>High Availability</title>

        <para>In a virtualized environment, guests can be quickly restarted
        when needed. The host is still up and running, so rebooting a system
        is a matter of restarting a process. This has the advantage that
        caching and other performance measures taken by the hypervisor are
        still available, which makes bootup times of guests quite fast.</para>

        <para>But even in case of host downtime, given the right architecture,
        guests can be quickly started up again. By providing a hardware
        abstraction in the virtualization layer, these technologies are able
        to start a guest on a different hardware environment (even with
        different hardware, although there are limits to this - the most
        obvious one being that the new hardware must support the same
        architecture and virtualization). Many virtualization solutions can
        host guest storage (the guests' disks) in image files which can be
        made highly available through high-performance NFS shares, cluster
        file system or storage synchronisation. If the host crashes, the guest
        storage is quickly made available on a different host and the guest is
        restarted.</para>
      </section>

      <section>
        <title>Resource optimization</title>

        <para>For most organizations, virtualization is one of the most
        effective ways to optimize resources in their data rooms. Regular
        Unix/Windows servers generally consume lots of power, cooling and
        floor space while still only offering 15% (or less) of actual resource
        consumption (CPU cycles). 85% of the time, the system is literally
        doing nothing but waiting. With virtualization, you can have resources
        utilized better, going towards a healthy 80% while still allowing room
        for sudden resource burst demands.</para>
      </section>

      <section>
        <title>Flexible change management</title>

        <para>The virtualization layer also offers a way to do flexible change
        management. Because guests are now more tangible, it is easier to make
        snapshots of entire guests, copy them around, upgrade one instance
        and, if necessary, roll back to the previous snapshot - all this in
        just a few minutes or less. You can't do this with dedicated
        installations.</para>
      </section>

      <section>
        <title>"Secure" isolation</title>

        <para>In a security-sensitive environment, isolation is a very
        important concept. It ensures that a system or service can only access
        those resources it needs to, while disallowing (and even hiding) the
        other resources. Virtualization allows architects to design the system
        so that it runs in its own operating system, so from the viewpoint of
        the service, it has access to those resources it needs, but sees no
        other. On the host layer, the guests can then be properly isolated so
        they cannot influence each other.</para>

        <para>Having separate operating systems is often seen as a thorough
        implementation of "isolation". Yes, there are a lot of other means to
        isolate services. Still, running a service in a virtualized operating
        system is not the summum of isolation. <link
        xlink:href="http://blog.nelhage.com/2011/08/breaking-out-of-kvm/">Breaking
        out of KVM</link> has been done in the past, and will most likely
        happen again. Other virtualization have seen their share of security
        vulnerabilities to this level as well.</para>
      </section>

      <section>
        <title>Simplified backup/restore</title>

        <para>For many organizations, a bare-metal backup/restore routine is
        much more resource hungry than regular file-based backup/restore. By
        using virtualization, bare-metal backup/restore of the guests is a
        breeze, as it is now back a matter of working with files (and
        processes). Ok, the name "bare-metal" might not work anymore here -
        and you'll still need to backup your hypervisor. But if your
        hypervisor (host) installation is very standardized, this is much
        faster and easier than before.</para>
      </section>

      <section>
        <title>Fast deployment</title>

        <para>By leveraging the use of guest images, it is easy to create a
        single image and then use it as a master template for other instances.
        Need a web serving cluster? Set up on, replicate and boot. Need a few
        more during high load? Replicate and boot a few more. It becomes just
        that easy.</para>
      </section>
    </section>

    <section>
      <title>Architecture</title>

      <para>To support the various advantages of virtualization mentioned
      earlier, we will need to take these into account in the architecture.
      For instance, high availability requires that the storage, on which the
      guests are running, is quickly (or even continuously) available on other
      systems so these can take over (or quickly boot) the guests. Also,
      supporting snapshotting means that we need to think about the process
      (steps) that are needed in order to support snapshotting.</para>

      <para>One of the services that will decide on the architecture the most
      is the high availability. Most virtualization products offer one or more
      methods for high availability. You can opt for an all-inclusive
      solution, such as Ganeti or libvirt. In the remainder of this chapter,
      we will focus on <emphasis>optional</emphasis> replicated storage based
      on DRBD, using regular file systems (so no cluster file systems or other
      distributed file systems). The replication will be triggered on
      host-level (not guest). If there is need for shared file systems, we
      will look into high-performance NFS systems.</para>

      <para>These decisions are based on the following, somewhat principle
      related, factors:</para>

      <itemizedlist>
        <listitem>
          <para>High availability of <emphasis>services</emphasis> is easy to
          accomplish without requiring additional components, such as file
          system replication or heart beats. Services like LDAP support
          replication out-of-the-box, and web servers are quite easy to set up
          in an active/active manner. As such high availability also provides
          the necessary flexibility for longer distances and doesn't incur
          additional, sometimes complex, technologies, this is the preferred
          method for high availability in the remainder of this book.</para>
        </listitem>

        <listitem>
          <para>When high availability can be provided by the services,
          offering high availability on the hypervisor level - while still
          very interesting - has a lower priority than offering decent
          performance. As a result, every performance-degrading method should
          be dismissed or at least made optional. And replication methods,
          such as DRBD, or cluster file systems, such as GFS2, do have a
          performance penalty.</para>
        </listitem>
      </itemizedlist>

      <para>Also, we will opt for regular KVM running inside screen sessions.
      The screen sessions allow us to easily manage KVM monitor commands. The
      console itself will be launched through VNC sessions. The sessions will
      by default not be started (as to not consume memory and resources) but
      can be started through the KVM monitor when needed. As a result, our
      virtualization architecture looks a bit like the following.</para>

      <figure>
        <title>Virtualization architecture</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-virtual-general.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>All the other aspects of the hypervisor level are the same as what
      we will have with our regular operating system design (which is defined
      further down). This is because at the hypervisor level, we will use
      Gentoo Linux as well. The flexibility of the operating system allows us
      to easily manage multiple guests in a secure manner (hence the secure
      containers displayed in the above picture). We will cover these secure
      containers later.</para>

      <section>
        <title>Administration</title>

        <para>Managing the guests entails the following use cases:</para>

        <itemizedlist>
          <listitem>
            <para>IMACD operations on the guest</para>
          </listitem>

          <listitem>
            <para>Operate a guest (stop, start, restart)</para>
          </listitem>
        </itemizedlist>

        <para>The regular IMACD operations are based on image management.
        Basic (master) guest images are managed elsewhere, and eventually
        published on a file server. The hosts, when needed, copy over this
        master image to the local file system. When a guest needs to be
        instantiated, it either uses a copy of this file (long-term guest) or
        a copy-on-write (short-term guest) stored in the proper directory
        after which it is launched.</para>

        <para>Similarly, removal of guests entails shutdown of the guest and
        removal of the image from the system. All this is easily
        scriptable.</para>
      </section>

      <section>
        <title>Monitoring</title>

        <para>Monitoring guests will be integrated in the monitoring component
        later. Basically, we want to be notified if a guest is not running
        anymore but should (process monitoring), or if a guest is not
        responsive anymore (ping reply monitoring).</para>
      </section>

      <section>
        <title>Security</title>

        <para>We mentioned secure containers before, so let's describe this
        bit in more detail.</para>

        <para>What we want to accomplish is that the virtual guests cannot
        interfere with each other. This is both permission-wise (for which we
        will use SELinux) as well as resources (for which we will use Linux
        cgroups).</para>

        <para>Permissions will be governed through SELinux' categories. The
        guests all run inside a SELinux domain already, so that
        vulnerabilities within the Qemu emulator (the user-space part of the
        hypervisor) cannot influence the host itself. However, if they all run
        inside the same SELinux domain, then they could influence each other.
        So what we will do is run each of them within a particular SELinux
        category, and make sure that their images also have this category
        assigned. </para>

        <para>Resources are governed through Linux cgroups, allowing
        administrators to put restrictions on various resources such as CPU,
        I/O, network usage, etc. On a hypervisor level, we want to support
        guests with differentiated resource requirements:</para>

        <itemizedlist>
          <listitem>
            <para>guaranteed resources (so the CPU shares and memory shares
            are assigned immediately)</para>
          </listitem>

          <listitem>
            <para>prioritized resources (so the CPU shares and memory shared
            are, when needed, preferably assigned to members of this
            group)</para>
          </listitem>

          <listitem>
            <para>shared resources (the rest ;-)</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>

    <section>
      <title>Deployment and uses</title>

      <para>Let's make all this a bit more tangible and look at how this would
      be accomplished.</para>

      <section>
        <title>File system structure</title>

        <para>Each host uses the same file system structure (standard) so that
        you can move images from one system to another without changing your
        underlying procedures. Let's say the images are stored in
        <filename>/srv/virt</filename> using the following structure:</para>

        <programlisting>/sr/virt
+- pending
+- base
`- guests
   +- hostname1
   |  +- rootfs.img
   |  +- otherfs.img
   |  +- settings.conf
   |  `- computed.conf
   +- hostname2
   `- ...</programlisting>

        <para>The <filename>pending</filename> location is where base image
        copies are placed first. Images in that directory are still in process
        of being transferred, or have been interrupted somewhere along. Once a
        copy is complete, the image will be moved from the pending to the
        <filename>base</filename> location. Guests then use copies (of
        copy-on-write) images from the base images, although this is of course
        not mandatory - new empty images can be created as well for other
        purposes. The base images allow you to quickly setup particular
        systems or prepared file systems for other purposes.</para>

        <para>The <filename>settings.conf</filename> file contains the
        information related to the guest. This includes MAC address
        information, guest image information (and options on how to attach
        them), etc. It is also wise to make this file easily manageable by
        both humans (so don't use special syntax) and tools (so don't use
        human language). The other configuration file,
        <filename>computed.conf</filename>, contains settings specific for
        running this guest on this host and is generated and updated by the
        scripts we use to manage the virtual images.</para>

        <programlisting>## Example settings.conf
HOSTNAME=pg1
DOMAINNAME=internal.genfic.com
MAC_ADDRESS=00:11:22:33:44:b3
VLAN=8
CPU=kvm64
SMP_DEFAULT=2 # Dual CPU
MEM_DEFAULT=1536 # 1.5 Gbyte of memory
RESOURCES=guaranteed # for cgroup management

IMAGES=IMAGE1,IMAGE2
IMAGE1=/srv/virt/guests/pg1/rootfs.img,if=virtio,cache=writeback
IMAGE2=/srv/virt/guests/pg1/postgresdb.img,if=virtio,cache=writeback</programlisting>

        <programlisting>## Example computed.conf
GDB=disabled
VNC_ADDRESS=vhost4-mgmt
VNC_PORT=14 # real port is 5914
SMP=2
MEM=2048 # 2 Gbyte of memory
STATE=running
SELINUX_CATEGORY=12
CGROUP=guests/dedicated/pg1</programlisting>
      </section>

      <section>
        <title>Interacting with KVM monitors</title>

        <para>The KVM monitor (actually Qemu/KVM monitor) allows
        administrators to manage the virtual guest specifics, such as
        hot-adding (or removing) devices, taking snapshots, etc. As we placed
        the KVM monitor on the standard output within screen, all the admin
        has to do (after logging in) is to attach to the monitor of the right
        virtual guest.</para>

        <programlisting>$ <command>screen -ls</command>
There are screens on:
   4872.kvm-pg1     (Detached)
   5229.kvm-www1    (Detached)
  14920.kvm-www2    (Detached)
$ <command>screen -x kvm-pg1</command>
(qemu) </programlisting>
      </section>
    </section>
  </section>

  <section>
    <title>Basic OS architecture</title>

    <para>When we position an operating system platform such as Gentoo Linux,
    quite a few aspects already need to be considered in its design. It isn't
    sufficient to just create an image (or installation procedure) and be done
    with it. We need to consider basic services on operating systems, such as
    backup/restore routines, updates &amp; upgrades, etc. Most of the
    infrastructure needed to accomplish all that will be talked about
    further.</para>

    <section>
      <title>Services</title>

      <para>When you are going to manage multiple servers, you will need some
      sort of centralized services. This doesn't require a daemon/server
      architecture for all services though, as we will see later on.</para>

      <figure>
        <title>Services for an operating system platform</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-platform-services.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The mentioned services on the above drawing are quite basic
      services, which you will need to properly manage in order to get a well
      functioning environment.</para>

      <section>
        <title>Access management services</title>

        <para>To access the system, mostly for administrative purposes,
        requires basic access methods towards the system. As we are using
        Gentoo Linux, the most probable component for this is OpenSSH. But in
        order to properly provide access services, we don't only look at the
        OpenSSH daemon itself, but also the centralized access management
        services (which will be OpenLDAP based) to easily manage what is
        called <emphasis>joiner/leaver processes</emphasis>.</para>

        <para>A joiner/leaver process is the process that needs to be taken
        when a person joins (or leaves) the organization. Proper processes
        should ensure that the account(s) that this person uses are only
        usable as long as the person is a member of the organization, and that
        his rights are properly managed. If you have hundreds of servers, it
        is of course not feasible to manually update the servers
        <filename>/etc/passwd</filename> and <filename>/etc/shadow</filename>
        files manually. You could still build some scripts that automatically
        create and modify these files, or even use a centralized configuration
        management set for that, but you will quickly hit boundaries.</para>
      </section>

      <section>
        <title>Monitoring services</title>

        <para>Monitoring services are used, not really to be informed when a
        service is down, but rather to quickly identify what is causing a
        service failure.</para>

        <para>Service failures, like "I cannot resolve IP addresses" or "The
        web site is not reachable" are difficult to debug if you are lacking
        monitoring. Proper monitoring implementations allow you to get an idea
        of the entire state of the architecture and its individual components.
        If monitoring tells you that the web server processes are running and
        that remote web site retrieval agents are still pulling in site
        details, then you're most likely to look at the connectivity between
        the client and the site (such as potential proxy servers or even
        networking or firewalls). On the other hand, if the monitoring is
        telling you that a web gateway daemon is not responsive, you'll
        quickly be able to handle the problem as you have a fairly good idea
        at where the problem lies.</para>
      </section>

      <section>
        <title>Backup services</title>

        <para>Although backups are not important, being able to restore stuff
        is - hence the need for backups ;-)</para>

        <para>Even on regular servers, backups will be important to support
        fast recovery from human errors or application malpractices. Users,
        including administrators, make mistakes. Being able to quickly recover
        from deleted files or modifications will save you hours of work
        later.</para>
      </section>

      <section>
        <title>Configuration management</title>

        <para>In order to properly update/upgrade the systems, as well as
        configure it to match the needs of the organization, you will need
        some configuration management approach. Whereas smaller deployments
        can be perfectly managed manually, decent configuration management
        allows you to quickly deploy new systems, reconfigure systems when
        needed, support testing of configuration changes, etc.</para>
      </section>
    </section>

    <section>
      <title>Architecture</title>

      <para>In our reference architecture, the given services will be filled
      in with the following components.</para>

      <figure>
        <title>Components for operating system platform</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-platform-components.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The activities involved with those components are described in the
      next few sections.</para>

      <section>
        <title>Flows and feeds</title>

        <para>The services that will be mostly important for the larger flows
        are the software management services (through Portage) and the
        backup/restore routines (through Bacula).</para>

        <figure>
          <title>Operating system feeds</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="images/02-platform-feeds.png"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>Let's first consider the <emphasis>software
        management</emphasis> part. As we are using Gentoo Linux, we will use
        Gentoo's Portage package management called Portage<indexterm>
            <primary>Portage</primary>
          </indexterm>. However, to support large-scale deployments, we will
        use the Portage binary package support. This allows us to build
        packages once, and make them available for others. We will discuss the
        build server for Gentoo later in this book.</para>

        <para>We can choose how we make the binary packages available from a
        number of methods:</para>

        <itemizedlist>
          <listitem>
            <para>Use a central file server on which the packages are hosted.
            We can use an NFS server for this, or any of the various other
            methods (including caching-enabled systems such as OpenAFS).
            </para>
          </listitem>

          <listitem>
            <para>Use a web server that serves the packages, and have Portage
            pull the packages from the web server</para>
          </listitem>
        </itemizedlist>

        <para>I prefer the use of a web server because it offers nice logging
        capabilities, and you can put in additional security measures (such as
        requiring the use of SSL with mutual authentication). Also, load
        balancing is quite simple, as is controlling all data flows (and req,
        uest queueing, etc.)</para>

        <para>The second flows is the backup/restore flows. These are governed
        by the Bacula backup software. Depending on the configuration, this
        might give a significant overhead (network-wise). As we are using
        virtualized systems, I suggest to use host-based snapshot methods for
        backing up entire virtual images (allowing for "bare-metal"
        recovery).</para>
      </section>

      <section>
        <title>Administration</title>

        <para>To administer the system (and the components hosted on it), we
        will use OpenSSH (for access to the system) and Puppet (for managing
        configuration settings).</para>

        <figure>
          <title>Operating system administration</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="images/02-platform-administration.png"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>Standard operator/administrator access to the operating system
        is handled through the SSH secure shell. The OpenSSH daemon will be
        configured to use a central user repository for its authentication of
        users. This allows administrators to, for instance, change their
        password on a single system and ensure that the new password is then
        in use for all other systems as well.</para>

        <para>The configuration management will be handled through Puppet,
        whose configuration repository will be managed through various
        version-controlled systems and eventually exported on NFS towards the
        systems. If needed, different NFS services or definitions can be used
        to limit which systems can see the configuration settings of other
        systems.</para>
      </section>

      <section>
        <title>Monitoring</title>

        <para>We will monitor the systems (and the components and services
        that we host further) through Icinga.</para>

        <figure>
          <title>Operating system monitoring</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="images/02-platform-monitoring.png"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>The icinga agent supports various plugins that allow us to
        monitor various aspects of the operating system and the services that
        run on it. The results of each "query" is then sent to the central
        Icinga database. The monitoring web interface, which we will discuss
        later, interacts with the database to visually represent the state of
        your environment.</para>
      </section>
    </section>

    <section>
      <title>The choice of Gentoo Hardened</title>

      <para>To increase security of the deployments, all systems in this
      reference architecture will use a Gentoo Hardened deployment. Within the
      Gentoo Linux community, Gentoo Hardened is a project that oversees the
      research, implementation and maintenance of security-oriented projects
      in Gentoo Linux. It focuses on delivering viable security strategies for
      high stability production environments and is therefor absolutely
      suitable for this reference architecture.</para>

      <para>Within our scope, we will implement all services on a Gentoo
      Hardened deployment with the following security measures in
      place:</para>

      <itemizedlist>
        <listitem>
          <para>PaX</para>
        </listitem>

        <listitem>
          <para>PIE/PIC/SSP</para>
        </listitem>

        <listitem>
          <para>SELinux as MAC</para>
        </listitem>

        <listitem>
          <para>grSecurity kernel improvements</para>
        </listitem>
      </itemizedlist>

      <para>The installation of a Gentoo Hardened system is similar to a
      regular Gentoo Linux one. You can find all necessary information on the
      Gentoo Hardened project page. Later, we'll describe how to use images of
      a (succesful) installation for seeding new servers and systems.</para>

      <section>
        <title>PaX</title>

        <para>The PaX<indexterm>
            <primary>PaX</primary>
          </indexterm> project (part of grSecurity) aims to update the Linux
        kernel with <link
        xlink:href="http://pax.grsecurity.net/docs/pax.txt">defense
        mechanisms</link> against exploitation of software bugs that allow an
        attacker access to the software's address space (memory). By
        exploiting this access, a malicious user could introduce or execute
        arbitrary code, execute existing code without the applications'
        intended behavior, or with different data than expected.</para>

        <para>One of the defence mechanisms introduced is NOEXEC<indexterm>
            <primary>NOEXEC</primary>
          </indexterm>. With this enabled, memory pages of an application
        cannot be marked writeable and executable. So either a memory page
        contains application code, but cannot be modified (kernel enforced),
        or it contains data and cannot be executed (kernel enforced). The
        enforcement methods used are beyond the scope of this book, but are
        described <link
        xlink:href="http://pax.grsecurity.net/docs/noexec.txt">online</link>.
        Enforcing NOEXEC does have potential consequences: some applications
        do not work when PaX enforces this behavior. Because of this, PaX
        allows administrators to toggle the enforcement on a per-binary basis.
        For more information about this, see the Hardened Gentoo PaX
        Quickstart document (see resources at the end of this chapter). Note
        that this also requires PIE/PIC built code (see later).</para>

        <para>Another mechanism used is ASLR<indexterm>
            <primary>ASLR</primary>
          </indexterm>, or Address Space Layout Randomization. This thwarts
        attacks that need advance knowledge of addresses (for instance through
        observation of previous runs). With ASLR enabled, the address space is
        randomized for each application, which makes it much more difficult to
        guess where a certain code (or data) portion is loaded, and as such
        attacks will be much more difficult to execute succesfully. This
        requires the code to be PIE built.</para>

        <para>To enable PaX, you will need to install the hardened-sources
        kernel in Gentoo Linux and configure it according to the instructions
        found on the Hardened Gentoo PaX Quickstart document. You should also
        install <command>paxctl</command><indexterm>
            <primary>paxctl</primary>
          </indexterm>.</para>

        <programlisting># <command>emerge hardened-sources</command>
# <command>emerge paxctl</command></programlisting>
      </section>

      <section>
        <title>PIE/PIC/SSP</title>

        <para>The given abbreviations describe how source code is built into
        binary, executable code.</para>

        <para>PIC<indexterm>
            <primary>PIC</primary>
          </indexterm> (Position Independent Code) is used for shared
        libraries to support the fact that they are loaded in memory
        dynamically (and without prior knowledge to the addresses). Whereas
        older methods use load-time relocation (where address pointers are all
        rewritten the moment the code is loaded in memory), PIC uses a higher
        abstraction of indirection towards data and function references. By
        building shared objects with PIC, relocations in the text segment in
        memory (which contains the application code) are not needed anymore.
        As such, these pages can be marked as non-writeable.</para>

        <para>To find out if you have libraries that still support text
        relocations<indexterm>
            <primary>text relocation</primary>
          </indexterm>, you can install the pax-utils package and scan your
        libraries for text relocations:</para>

        <programlisting># <command>emerge pax-utils</command>
$ <command>scanelf -lpqt</command>
TEXTREL  /opt/Citrix/ICAClient/libctxssl.so</programlisting>

        <para>In the above example, the libctxssl.so file is not built with
        PIC and as such could be more vulnerable to attacks as its
        code-containing memory pages might not be marked as
        non-writeable.</para>

        <para>With PIE<indexterm>
            <primary>PIE</primary>
          </indexterm> (Position Independent Executables) enabled, executables
        are built in a fashion similar to shared objects: their base address
        can be relocated and as such, PaX' ASLR method can be put in effect to
        randomize the address in use. An application binary that is PIE-built
        will show up as a shared object file rather than an executable file
        when checking its ELF header</para>

        <programlisting>$ <command>readelf -h /bin/ls | grep Type</command>
  Type:            DYN (Shared object file)

$ <command>readelf -h /opt/Citrix/ICAClient/wfcmgr.bin | grep Type</command>
  Type:            EXEC (Executable file)</programlisting>

        <para>SSP<indexterm>
            <primary>SSP</primary>
          </indexterm> finally stands for Stack Smashing Protection. Its
        purpose is to add in additional buffers after memory allocations (for
        variables and such) which contain a cryptographic marker (often called
        the canary). When an overflow occurs, this marker is also overwritten
        (after all, that's how overflows work). When a function would return,
        this marker is first checked to see if it is still valid. If not, then
        an overflow has occurred and the application is stopped
        abruptly.</para>
      </section>

      <section>
        <title>Checking PaX and PIE/PIC/SSP results</title>

        <para>If you want to verify the state of your system after applying
        the security measures identified earlier, install paxtest and run it.
        The application supports two modes: kiddie and blackhat. The blackhat
        test gives the worst-case scenario back whereas the kiddie-mode runs
        tests that are more like the ones script-kiddies would run. The
        paxtest application simulates certain attacks and presents plausible
        results to the reader.</para>

        <para>A full explanation on the tests ran can be found in the
        <filename>/usr/share/doc/paxtest-*/README</filename> file.</para>

        <programlisting># <command>emerge paxtest</command>
# <command>paxtest blackhat</command>

PaXtest - Copyright(c) 2003,2004 by Peter Busser &lt;peter@adamantix.org&gt;
Released under the GNU Public Licence version 2 or later

Writing output to paxtest.log
It may take a while for the tests to complete
Test results:
PaXtest - Copyright(c) 2003,2004 by Peter Busser &lt;peter@adamantix.org&gt;
Released under the GNU Public Licence version 2 or later

Mode: blackhat
Linux hpl 3.1.6-hardened #1 SMP PREEMPT Tue Dec 27 13:49:05 CET 2011 \
  x86_64 Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz GenuineIntel GNU/Linux

Executable anonymous mapping             : Killed
Executable bss                           : Killed
Executable data                          : Killed
Executable heap                          : Killed
Executable stack                         : Killed
Executable shared library bss            : Killed
Executable shared library data           : Killed
...
Writable text segments                   : Killed
</programlisting>

        <para>These tests will try to write data and then execute it. The
        tests do this in different locations to verify if the memory
        protection measures are working. Killed means that it works as the
        attempt is stopped.</para>

        <programlisting>Executable anonymous mapping (mprotect)  : Killed
Executable bss (mprotect)                : Killed
Executable data (mprotect)               : Killed
Executable heap (mprotect)               : Killed
Executable stack (mprotect)              : Killed
Executable shared library bss (mprotect) : Killed
Executable shared library data (mprotect): Killed
</programlisting>

        <para>These are virtually the same tests as before, but now the
        application first tries to reset or change the protection bits on the
        pages using mprotect.</para>

        <programlisting>Anonymous mapping randomisation test     : 33 bits (guessed)
Heap randomisation test (ET_EXEC)        : 13 bits (guessed)
Heap randomisation test (PIE)            : 40 bits (guessed)
Main executable randomisation (ET_EXEC)  : No randomisation
Main executable randomisation (PIE)      : 32 bits (guessed)
Shared library randomisation test        : 33 bits (guessed)
Stack randomisation test (SEGMEXEC)      : 40 bits (guessed)
Stack randomisation test (PAGEEXEC)      : 40 bits (guessed)
</programlisting>

        <para>The randomisation tests try to find out which level of
        randomisation is put in place. Although randomisation by itself does
        not offer protection, it obscures the view malicious users have on the
        memory structures. The higher the randomisation, the better. On Gentoo
        Hardened, (almost) all binaries are PIE.</para>

        <programlisting>Return to function (strcpy)              : paxtest: return address \
                                           contains a NULL byte.
Return to function (memcpy)              : Vulnerable
Return to function (strcpy, PIE)         : paxtest: return address \
                                           contains a NULL byte.
Return to function (memcpy, PIE)         : Vulnerable
</programlisting>

        <para>These types of attacks are very difficult to thwart by kernel
        protection measures only. The author of the paxtest application has
        put those in because he can, even though he knows PaX does not protect
        against them. In effect, he tries to show users that PaX is not an
        all-safe method and that additional security layers are still
        important.</para>
      </section>

      <section>
        <title>SELinux as MAC</title>

        <para>With a MAC<indexterm>
            <primary>MAC</primary>
          </indexterm> (Mandatory Access Control<indexterm>
            <primary>Mandatory Access Control</primary>
          </indexterm>), the system administrator can control which accesses
        are allowed and which not, and can enforce that the user cannot
        override this. Regular access patterns in Linux are discretionary, so
        the user can define this himself. In this book, we will use
        SELinux<indexterm>
            <primary>SELinux</primary>
          </indexterm> as the MAC system. Another supported MAC in Gentoo
        Hardened is grSecurity's RBAC model.</para>

        <para>Installing and configuring Hardened Gentoo with SELinux is
        described in the Gentoo SELinux handbook. It is seriously recommended
        to read through this resource a few times, as SELinux is not just
        about enabling a feature - it is a change in the security model and
        requires experience with it.</para>

        <para>We will use the SELinux strict policy (so no unconfined domains)
        for regular services, or MCS (without unconfined domains) when we want
        to use the multi-tenancy support.</para>

        <programlisting>$ <command>id -Z</command>
staff_u:staff_r:staff_t

# <command>sestatus</command>
SELinux status:                 enabled
SELinuxfs mount:                /selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             strict
Current mode:                   enforcing
Mode from config file:          enforcing
Policy MLS status:              disabled
Policy deny_unknown status:     denied
Max kernel policy version:      26</programlisting>
      </section>

      <section>
        <title>grSecurity kernel improvements</title>

        <para>Next to the previously mentioned grSecurity updates, grSecurity
        also adds in additional kernel protection measures. This includes
        additional hardening on chroot jails (to make it a lot more difficult
        to break out of a chroot) and file system abuse (like getting
        information from pseudo-filesystems to improve attacks).</para>

        <para>For more information on enabling grSecurity, see the Gentoo
        grSecurity v2 Guide.</para>
      </section>

      <section>
        <title>Using IMA and EVM</title>

        <para>Another set of security subsystems available in recent Linux
        kernels are the Integrity Measurement Architecture and Extended
        Verification Modules subsystems.</para>

        <para>With IMA<indexterm>
            <primary>IMA</primary>
          </indexterm>, the integrity of files is validated (checksum or
        digital signature) against the recorded value in the extended
        attribute of that file. If the integrity matches, then the system
        allows to read (and if it isn't a digital signature, even modify) the
        file. If the checksum doesn't match, then the access to the file is
        prohibited.</para>

        <para>EVM<indexterm>
            <primary>EVM</primary>
          </indexterm> then ensures that the extended attributes of the file
        are not tampered with (as it stores the security information from IMA
        as well as SELinux information). This is accomplished using a HMAC
        value or a digital signature of the security related extended
        attributes. Because of the use of cryptographic methods, offline
        tampering of this data is not that simple - the attacker needs access
        to the key used by the HMAC or even the private key used for
        generating the signatures.</para>

        <para>For more information on enabling IMA/EVM, see the Gentoo
        Integrity subproject documentation.</para>
      </section>
    </section>

    <section>
      <title>Deployment and uses</title>

      <section>
        <title>Partitioning and LVM</title>

        <para>In our architecture, we will be using directly attached storage
        (so no SAN nor NAS for every possible file system) and deal with the
        consequences of having distributed storage differently. One of the
        methods we will be using is to use LVM wherever we can, including for
        the root file system. It is recommended that the internal storage is
        somewhat protected against disk failure through RAID. Although the
        author is a proponent of RAID1, <link
        xlink:href="http://assets.en.oreilly.com/1/event/27/Linux%20Filesystem%20Performance%20for%20Databases%20Presentation.pdf">tests</link>
        have shown that RAID5 performs equally well.</para>

        <para>We will use a non-LVM partition (RAID1 protected) for the /boot
        location, and use LVM volumes for the rest. We will also define
        different volume groups for system versus data.</para>

        <programlisting># <command>pvcreate /dev/md1</command>
# <command>vgcreate vg_system /dev/md1</command>
# <command>lvcreate -l 20G -n lv_root vg_system</command>
# <command>lvcreate -l 10G -n lv_home vg_system</command></programlisting>

        <para>Through this approach, the root file system will be hosted on
        <filename>/dev/mapper/vg_system-lv_root</filename> and as such be
        expandable (if necessary) as well as protected by the underlying RAID
        system. If you keep enough free space in the volume group, you can
        work with snapshots to support flexible backup methods.</para>
      </section>

      <section>
        <title>Selection of used system software</title>

        <para>The following set of system software components will be
        installed (and thus part of the base setup).</para>

        <itemizedlist>
          <listitem>
            <para>syslog-ng, as the acting system logger and system log
            daemon</para>
          </listitem>

          <listitem>
            <para>vixie-cron, as the acting cron daemon (for running scheduled
            tasks in the background)</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Network settings</title>

        <para>We will be using IPv6 exclusively in this architecture, but for
        some applications, we still need to support IPv4. When this is the
        case, we will try to only use 127.0.0.1.</para>
      </section>
    </section>
  </section>

  <section>
    <title>Resources</title>

    <para>For more information about the topics in this chapter, you can
    divulge yourself in the information available at the following
    resources...</para>

    <para>Gentoo Hardened:</para>

    <itemizedlist>
      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/pax-quickstart.xml">Hardened
        Gentoo PaX Quickstart</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link xlink:href="http://hardened.gentoo.org">Gentoo Hardened
        project page</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://eli.thegreenplace.net/2011/11/03/position-independent-code-pic-in-shared-libraries/">Position
        Independent Code</link> in shared libraries</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/pic-guide.xml">Introduction
        to Position Independent Code</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://blog.fpmurphy.com/2008/06/position-independent-executables.html">Position
        Independent Executables</link></para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/selinux/selinux-handbook.xml">Gentoo
        SELinux Handbook</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/grsecurity.xml">Gentoo
        grSecurity v2 Guide</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/integrity">Gentoo
        Hardened Integrity subproject</link> (Gentoo Linux)</para>
      </listitem>
    </itemizedlist>

    <para>KVM virtualization &amp; Ganeti:</para>

    <itemizedlist>
      <listitem>
        <para><link xlink:href="http://www.lancealbertson.com/">Lance
        Albertson's blog</link> (high focus on Ganeti and Gentoo)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://docs.ganeti.org/ganeti/current/html/">Ganeti
        documentation</link></para>
      </listitem>

      <listitem>
        <para><link xlink:href="http://notes.ceondo.com/ganeti/">Ganeti
        deployment notes</link> (Condo)</para>
      </listitem>
    </itemizedlist>
  </section>
</chapter>
